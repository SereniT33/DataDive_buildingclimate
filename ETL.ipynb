{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7772f7c-b0c1-4fb9-826d-f6bc5e8da600",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook uses Google Open Building dataset for Indonesia in order to showcase the following data science skills:\n",
    "1. to extract large geospatial datasets from Google Open Buildings\n",
    "2. to transform datasets \n",
    "3. to load datasets for the further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb5308f-493c-4949-8f4d-2d6c8665802d",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9827c1a9-39bc-4c68-a40e-c8fd6f8c6932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in c:\\users\\seren\\anaconda3\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: shapely>=1.8.0 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from geopandas) (2.0.1)\n",
      "Requirement already satisfied: fiona>=1.8.21 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from geopandas) (1.9.4.post1)\n",
      "Requirement already satisfied: packaging in c:\\users\\seren\\anaconda3\\lib\\site-packages (from geopandas) (21.3)\n",
      "Requirement already satisfied: pandas>=1.4.0 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from geopandas) (1.4.4)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from geopandas) (3.6.0)\n",
      "Requirement already satisfied: click~=8.0 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from fiona>=1.8.21->geopandas) (8.0.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from fiona>=1.8.21->geopandas) (21.4.0)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\seren\\anaconda3\\lib\\site-packages (from fiona>=1.8.21->geopandas) (2022.9.14)\n",
      "Requirement already satisfied: six in c:\\users\\seren\\anaconda3\\lib\\site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\seren\\anaconda3\\lib\\site-packages (from fiona>=1.8.21->geopandas) (4.11.3)\n",
      "Requirement already satisfied: click-plugins>=1.0 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from pandas>=1.4.0->geopandas) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from pandas>=1.4.0->geopandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from packaging->geopandas) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\seren\\anaconda3\\lib\\site-packages (from click~=8.0->fiona>=1.8.21->geopandas) (0.4.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from importlib-metadata->fiona>=1.8.21->geopandas) (3.8.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\seren\\anaconda3\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\seren\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ef9a96-6736-4af4-9eab-ccb4da579c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f1953-acee-4604-a270-2a0dae61744b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf81ba8-31dc-4300-9854-d58d7c2b37b6",
   "metadata": {},
   "source": [
    "Google Open Building dataset can be found and downloaded at: https://sites.research.google/open-buildings/\n",
    "\n",
    "For a easier data access, I chose to download region-specific datasets, upload them on a personal Google Drive, then access them by mounting the Drive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee7733e-55ad-4f13-b0fa-2906c157dd18",
   "metadata": {},
   "source": [
    "### (Optional) Mounting Google Drive for data access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ab13209-8eb8-420d-8b82-b4c2d62489f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_47224\\1050275017.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630495e5-77d0-4e13-86e1-9212c98b4dce",
   "metadata": {},
   "source": [
    "# Extract the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd464e84-b2fd-4693-b015-bc11c48c5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [['/content/gdrive/MyDrive/DataDive/indonesia1.csv.gz',\n",
    "              '/content/gdrive/MyDrive/DataDive/indonesia2.csv.gz',\n",
    "              '/content/gdrive/MyDrive/DataDive/indonesia3.csv.gz',\n",
    "              '/content/gdrive/MyDrive/DataDive/indonesia4.csv.gz']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b6c331-46f8-4658-a3f1-bcb5761c2908",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad26c6b7-2a89-4c73-80a5-c47b04bef4d3",
   "metadata": {},
   "source": [
    "As some Open Building datasets are too large to process on notebooks, I decided to randomly sample rows. The code below randomly sample rows from gzipped CSV files and reads them as a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f115b53-acae-4777-b466-2c32fc13a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read 10000 random rows\n",
    "def sample_rows_from_csv_gz(filename: str, n: int = 10000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Randomly sample n rows from a gzipped CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): Path to the gzipped CSV file.\n",
    "    - n (int): Number of rows to sample. Default is 10,000.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A dataframe containing the sampled rows.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the total number of rows in the file\n",
    "    with gzip.open(filename, \"rt\") as f:\n",
    "        total_rows = sum(1 for row in tqdm(f, desc=\"Counting rows\"))\n",
    "\n",
    "    # If there are fewer than n rows, return all rows\n",
    "    if total_rows <= n:\n",
    "        return pd.read_csv(filename, compression='gzip')\n",
    "\n",
    "    # Calculate the number of rows to skip\n",
    "    skip_rows = total_rows - n\n",
    "    # Randomly select rows to skip\n",
    "    skipped_rows = random.sample(range(1, total_rows), skip_rows)\n",
    "\n",
    "    # Read the CSV file with progress updates and concatenate the chunks\n",
    "    chunks = pd.read_csv(filename, compression='gzip', skiprows=skipped_rows, iterator=True, chunksize=1000)\n",
    "    df = pd.concat(tqdm(chunks, total=n//1000, desc=\"Loading data\"), ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0e0dbc-bb44-4c95-b1ad-1225c83beaaa",
   "metadata": {},
   "source": [
    "Using the function above, we iterate through the files to randomly sample 10,000 rows from each gzipped CSV files, then append them into one dataframe for a country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308bb4b4-c3c4-4121-8290-6d70cd5c8f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Declare dataframe\n",
    "    df = pd.DataFrame()\n",
    "    # Get list of files from the local files\n",
    "    all_files = ['/content/gdrive/MyDrive/DataDive/indonesia1.csv.gz',\n",
    "                 '/content/gdrive/MyDrive/DataDive/indonesia2.csv.gz',\n",
    "                 '/content/gdrive/MyDrive/DataDive/indonesia3.csv.gz',\n",
    "                 '/content/gdrive/MyDrive/DataDive/indonesia4.csv.gz']\n",
    "    # Iterate through the files and append to current dataframe\n",
    "    for file in all_files:\n",
    "      df = df.append(sample_rows_from_csv_gz(file))\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03621c5b-fb1b-40c2-b7e3-a471bc89f6dc",
   "metadata": {},
   "source": [
    "### Confidence Level "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096aaa83-22ac-40a8-b62b-5c3f3423c0e3",
   "metadata": {},
   "source": [
    "As the Open Buildings data is subject to both omission and commission errors, it is recommended to choose the confidence score threshold at which buildings are filtered out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34be85e-13d8-4b20-ad16-7bd4207d2f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to include confidence level of 85% or above\n",
    "high_confidence = 0.85 #Can be adjusted\n",
    "df = df[df['confidence'] >= high_confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b58bc2-8ef5-48bb-badf-802527826f10",
   "metadata": {},
   "source": [
    "### Visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c58be-5025-4a3f-9866-839b620be389",
   "metadata": {},
   "source": [
    "The visualization below shows the geospatial distribution of the dataframe, df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12203a32-c692-4416-869d-977e89775b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['geometry'] = df['geometry'].apply(wkt.loads)\n",
    "df = data.set_geometry('geometry')\n",
    "df.boundary.head()\n",
    "    \n",
    "#Plot all Google Open Buildings Coverage\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "df[:100000].boundary.plot(ax=ax, color='blue')\n",
    "ax.set_title(\"Indonesia Building Footprints\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11051118-7d5c-4ce8-990e-331b025dc255",
   "metadata": {},
   "source": [
    "# Transform the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c804d2-202d-42aa-bd1f-ad92e76e85af",
   "metadata": {},
   "source": [
    "### Reverse Geocoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d8578b-af19-4a06-a890-214f75ec2a84",
   "metadata": {},
   "source": [
    "Nominatim API is used to convert geographic coordinates into a human-readable address and associate building footprint data with specific geographic locations and building attributes such as type and class. More information on the Nominatim API can be found here: https://nominatim.org/release-docs/latest/api/Overview/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f85a0-323b-4d11-a302-b58127fab43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_country = 'Indonesia' #Can be adjusted\n",
    "\n",
    "# Define a function to get an address from given latitude and longitude using the Nominatim API.\n",
    "def get_address_from_coords(lat, lon):\n",
    "    # Base URL for the Nominatim reverse geocoding API\n",
    "    base_url = \"https://nominatim.openstreetmap.org/reverse\"\n",
    "    # Parameters to be passed with the API request\n",
    "    params = {\n",
    "        \"format\": \"json\",\n",
    "        \"lat\": lat,\n",
    "        \"lon\": lon\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json() # Parse the JSON response to get the address data\n",
    "        return data\n",
    "    except requests.RequestException as e:\n",
    "        # Handle any exceptions related to the request, such as timeouts, connectivity issues, etc.\n",
    "        print(f\"Error fetching data for lat={lat}, lon={lon}. Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da16dc7-1b46-4e54-9fbd-9e650085d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry point for the script execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Display the number of buildings that we are going to fetch data for\n",
    "    print(f\"Finding administrative divisions for {len(df)} buildings \\n\\n\")\n",
    "\n",
    "    # Loop through each building in the dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        # Fetch the human-readable address for the given coordinates of the building\n",
    "        address = get_address_from_coords(row.latitude, row.longitude)\n",
    "\n",
    "        # If an address is found and it is located in the chosen country, update the dataframe with the relevant details\n",
    "        if address and address.get('address', {}).get('country') == chosen_country:\n",
    "            df.at[index, 'Country'] = address['address'].get('country', '')\n",
    "            df.at[index, 'Province'] = address['address'].get('province', '')\n",
    "            df.at[index, 'County'] = address['address'].get('county', '')\n",
    "            df.at[index, 'Country_code'] = address['address'].get('country_code', '')\n",
    "            df.at[index, 'State'] = address['address'].get('state', '')\n",
    "            df.at[index, 'ISO3166-2-lvl4'] = address['address'].get('ISO3166-2-lvl4', '')\n",
    "            df.at[index, 'Type'] = address.get('type', '')\n",
    "            df.at[index, 'Class'] = address.get('class', '')\n",
    "\n",
    "\n",
    "        # Print progress for each row to track the process\n",
    "        print(f\"Row <------> {index+1} written <------> {address}\")\n",
    "        2\n",
    "        # Pause for 1 second (Nominatim's usage policy)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb92a7a-43ce-43b4-a1a7-8b299bcd0ae6",
   "metadata": {},
   "source": [
    "### Extract Building Height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49c239-90e6-438d-a50d-88bdb01ed27d",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
